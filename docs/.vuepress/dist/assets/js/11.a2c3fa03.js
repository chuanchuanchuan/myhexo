(window.webpackJsonp=window.webpackJsonp||[]).push([[11],{72:function(t,e,a){"use strict";a.r(e);var n=a(0),s=Object(n.a)({},function(){var t=this,e=t.$createElement,a=t._self._c||e;return a("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[a("p",[t._v("#对应代码如下")]),t._v(" "),a("div",{staticClass:"language-java extra-class"},[a("pre",{pre:!0,attrs:{class:"language-java"}},[a("code",[t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("package")]),t._v(" hbase"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hadoop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("conf")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Configuration")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hadoop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("fs")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Path")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hadoop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hbase")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("HBaseConfiguration")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hadoop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hbase"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("client")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Put")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hadoop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hbase"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("io")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("ImmutableBytesWritable")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hadoop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hbase"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mapreduce")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("TableMapReduceUtil")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hadoop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hbase"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("util")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Bytes")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hadoop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("io")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("*"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hadoop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mapreduce")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Job")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hadoop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mapreduce")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("Mapper")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hadoop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mapreduce"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lib"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("input")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("FileInputFormat")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n"),a("span",{pre:!0,attrs:{class:"token keyword"}},[t._v("import")]),t._v(" "),a("span",{pre:!0,attrs:{class:"token namespace"}},[t._v("org"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("apache"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("hadoop"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("mapreduce"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("lib"),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),t._v("input")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(".")]),a("span",{pre:!0,attrs:{class:"token class-name"}},[t._v("SequenceFileInputFormat")]),a("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(";")]),t._v("\n")])])]),t._v(" "),a("div",{staticClass:"language- extra-class"},[a("pre",{pre:!0,attrs:{class:"language-text"}},[a("code",[t._v('import java.io.IOException;\nimport java.text.DateFormat;\nimport java.text.SimpleDateFormat;\nimport java.util.*;\nimport java.util.regex.Matcher;\nimport java.util.regex.Pattern;\n\n/**\n * Created by lcc on 2017/10/26.\n */\npublic class FromWeibo {\n\n    public static class ToHbaseMap extends Mapper<BytesWritable, MapWritable, ImmutableBytesWritable, Put>{\n        protected Date getPostDate(String down, String s){\n            Date postdate=null;\n            DateFormat downdf = new SimpleDateFormat("yyyy-MM-dd HH:mm");\n            try {\n                Date downd = downdf.parse(down);\n                String reg = "<p class=\\"release_date\\">(.*?)</p>";\n                Pattern pattern = Pattern.compile(reg);\n\n                Matcher matcher = pattern.matcher(s);\n                DateFormat df = new SimpleDateFormat("yyyy-MM-dd HH:mm");\n                DateFormat df2 = new SimpleDateFormat("MM月dd日 HH:mm");\n                if (matcher.find()) {\n                    String out = matcher.group(1);\n                    out = out.trim();\n                    if (!out.equals("")) {\n                        try {\n                            postdate = df.parse(out);\n                        } catch (Exception e) {\n                            try {\n                                postdate = df2.parse(out);\n                                postdate.setYear(117);\n                            } catch (Exception e2) {\n                                String reg2 = "[1-9]\\\\d*";\n                                Pattern pattern2 = Pattern.compile(reg2);\n                                Matcher matcher2 = pattern2.matcher(out.trim());\n                                if (matcher2.find()) {\n                                    int m = Integer.parseInt(matcher2.group());\n                                    postdate=new Date(downd.getTime()-m*60*1000);\n                                } else {\n                                    postdate=downd;\n                                }\n                            }\n                        }\n                    }\n                }\n            }\n            catch (Exception ex) {\n\n            }\n            return postdate;\n        }\n        protected String getPostContent(String s) {\n            String content = "";\n            String reg = "<p class=\\"content\\">(.*?)</p>";\n            Pattern pattern = Pattern.compile(reg);\n            Matcher matcher = pattern.matcher(s);\n            if (matcher.find()) {\n                content = matcher.group(1);\n            }\n            return content;\n        }\n        protected Date getRepostDate(String s){\n            Date d=null;\n            DateFormat df = new SimpleDateFormat("yyyy-MM-dd HH:mm");\n            try{\n                d=df.parse(s);\n            }catch (Exception e) {\n\n            }\n            return d;\n        }\n        protected void map(BytesWritable key, MapWritable value, Context context) throws IOException,InterruptedException{\n            Set<Writable> vs = value.keySet();\n            Iterator<Writable> it = vs.iterator();\n            int i = 0;\n            List<String> outkey=new LinkedList<String>();\n            List<String> outvalue=new LinkedList<String>();\n            while (it.hasNext()) {\n                Writable wt=it.next();\n                outkey.add(wt.toString());\n                Writable wvalue=value.get(wt);\n                outvalue.add(wvalue.toString());\n            }\n\n\n            try {\n                if (outvalue.get(outkey.indexOf("type")).equals("q")) {\n                    String down = outvalue.get(outkey.indexOf("download_date"));\n                    String s = outvalue.get(outkey.indexOf("format_content"));\n\n                    //被转发用户相关\n                    String forward_user_url = outvalue.get(outkey.indexOf("forward_user_url"));\n                    String forward_author = outvalue.get(outkey.indexOf("forward_author"));\n                    String forward_uid = outvalue.get(outkey.indexOf("forward_uid"));\n                    String verified = outvalue.get(outkey.indexOf("verified"));\n\n                    //被转发微博相关\n                    String refer_url = outvalue.get(outkey.indexOf("refer_url"));\n                    String post_source = outvalue.get(outkey.indexOf("post_source"));\n                    String forward_url = outvalue.get(outkey.indexOf("forward_url"));\n                    Date postdate = getPostDate(down, s);\n                    String Post = getPostContent(s);\n\n                    //转发微博信息\n                    Date release_date = getRepostDate(outvalue.get(outkey.indexOf("release_date")));\n                    String title = outvalue.get(outkey.indexOf("title"));\n                    String content = outvalue.get(outkey.indexOf("content"));\n                    String comments_count = outvalue.get(outkey.indexOf("comments_count"));\n                    String url = outvalue.get(outkey.indexOf("url"));\n                    String attitudes_count = outvalue.get(outkey.indexOf("attitudes_count"));\n                    String quote_count = outvalue.get(outkey.indexOf("quote_count"));\n\n                    //发表者相关信息\n                    String author = outvalue.get(outkey.indexOf("author"));\n                    String user_url = outvalue.get(outkey.indexOf("user_url"));\n                    String uid = outvalue.get(outkey.indexOf("uid"));\n\n                    //媒体来源\n                    String media_id = outvalue.get(outkey.indexOf("media_id"));\n                    String media_name = outvalue.get(outkey.indexOf("media_name"));\n\n                    //入库\n                    if (postdate != null && release_date != null) {\n                        DateFormat outdf = new SimpleDateFormat("yyyy-MM-dd HH:mm");\n                        byte[] bRowKey = Bytes.toBytes(url);\n                        ImmutableBytesWritable rowkey = new ImmutableBytesWritable(bRowKey);\n                        Put put = new Put(bRowKey);\n\n\n                        //"forward_user"列族\n                        put.addImmutable("forward_user".getBytes(), "forward_user_url".getBytes(), forward_user_url.getBytes());\n                        put.addImmutable("forward_user".getBytes(), "forward_author".getBytes(), forward_author.getBytes());\n                        put.addImmutable("forward_user".getBytes(), "forward_uid".getBytes(), forward_uid.getBytes());\n                        put.addImmutable("forward_user".getBytes(), "verified".getBytes(), verified.getBytes());\n\n                        //"forward_weibo"列族\n                        put.addImmutable("forward_weibo".getBytes(), "refer_url".getBytes(), refer_url.getBytes());\n                        put.addImmutable("forward_weibo".getBytes(), "post_source".getBytes(), post_source.getBytes());\n                        put.addImmutable("forward_weibo".getBytes(), "forward_url".getBytes(), forward_url.getBytes());\n                        put.addImmutable("forward_weibo".getBytes(), "postdate".getBytes(), outdf.format(postdate).getBytes());\n                        put.addImmutable("forward_weibo".getBytes(), "Post".getBytes(), Post.getBytes());\n\n\n                        //"post"列族\n                        put.addImmutable("post".getBytes(), "release_date".getBytes(), outdf.format(release_date).getBytes());\n                        put.addImmutable("post".getBytes(), "title".getBytes(), title.getBytes());\n                        put.addImmutable("post".getBytes(), "content".getBytes(), content.getBytes());\n                        put.addImmutable("post".getBytes(), "comments_count".getBytes(), comments_count.getBytes());\n                        put.addImmutable("post".getBytes(), "url".getBytes(), url.getBytes());\n                        put.addImmutable("post".getBytes(), "attitudes_count".getBytes(), attitudes_count.getBytes());\n                        put.addImmutable("post".getBytes(), "quote_count".getBytes(), quote_count.getBytes());\n\n\n                        //"poster"列族\n                        put.addImmutable("poster".getBytes(), "author".getBytes(), author.getBytes());\n                        put.addImmutable("poster".getBytes(), "user_url".getBytes(), user_url.getBytes());\n                        put.addImmutable("poster".getBytes(), "uid".getBytes(), uid.getBytes());\n\n\n                        //"media"列族\n                        put.addImmutable("media".getBytes(), "media_id".getBytes(), media_id.getBytes());\n                        put.addImmutable("media".getBytes(), "media_name".getBytes(), media_name.getBytes());\n\n                        context.write(rowkey, put);\n                    }\n                }\n            }catch (Exception ex)\n            {\n\n            }\n\n        }\n    }\n    public static void main(String[] args) throws Exception {\n        System.setProperty("hadoop.home.dir","C:\\\\hadoop" );\n        Configuration conf = HBaseConfiguration.create();\n        conf.set("hbase.zookeeper.quorum", "TjuBD");\n        conf.set("hbase.zookeeper.property.clientPort", "2181");\n        conf.set("dfs.socket.timeout", "180000");\n        Path seqFile = new Path("hdfs://172.28.9.62:8020/weibo/201701");\n        conf.set("io.compression.codecs", "com.hadoop.compression.lzo.LzoCodec");\n        conf.set("fs.default.name", "hdfs://172.28.9.62:8020");\n        conf.set("mapreduce.input.fileinputformat.input.dir.recursive", "True");\n        conf.set("hadoop.job.user", "hadoop");\n        conf.set("mapreduce.framework.name", "yarn");\n        conf.set("mapreduce.jobtracker.address", "172.28.9.62:9001");\n        conf.set("yarn.resourcemanager.hostname", "172.28.9.62");\n        conf.set("yarn.resourcemanager.admin.address", "172.28.9.62:8033");\n        conf.set("yarn.resourcemanager.address", "172.28.9.62:8032");\n        conf.set("mapreduce.job.jar", "C:\\\\Users\\\\lcc\\\\Desktop\\\\readfile\\\\target\\\\readfile-1.0-SNAPSHOT-jar-with-dependencies.jar");\n        conf.set("yarn.resourcemanager.resource-tracker.address", "172.28.9.62:8036");\n        conf.set("mapreduce.app-submission.cross-platform", "true");\n        conf.set("yarn.resourcemanager.scheduler.address", "172.28.9.62:8030");\n        Job job = Job.getInstance(conf, "FromWeiboToHbase");\n        job.setJarByClass(FromWeibo.class);\n        job.setInputFormatClass(SequenceFileInputFormat.class);\n        FileInputFormat.setInputPaths(job, seqFile);\n        job.setMapperClass(ToHbaseMap.class);\n        TableMapReduceUtil.initTableReducerJob("weibo",null,job);\n        job.setNumReduceTasks(0);\n        TableMapReduceUtil.addDependencyJars(job);\n        System.exit(job.waitForCompletion(true)?0:1);\n\n    }\n}\n\n')])])])])},[],!1,null,null,null);e.default=s.exports}}]);